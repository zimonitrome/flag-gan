{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from models import Generator, Discriminator\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torchvision.utils as vutils\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"../data/training_data\"\n",
    "batch_size = 300\n",
    "epochs = 10\n",
    "lr = 1.5e-4\n",
    "betas = (0.5, 0.99)\n",
    "weight_decay = 1e-4\n",
    "epoch_test_interval = 1\n",
    "batch_test_interval = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will run on cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if device == \"cuda\":\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "print(f\"Will run on {device}.\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "noise = Variable(torch.randn(1, 100, 1, 1)).to(device)\n",
    "test_noise = Variable(torch.randn(9, 100, 1, 1)).to(device)\n",
    "\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGBA')\n",
    "\n",
    "\n",
    "def get_flag_loader(dir=data, batch_size=batch_size, shuffle=True):\n",
    "    transform = transforms.ToTensor()\n",
    "    flag_dataset = datasets.ImageFolder(\n",
    "        root=dir, transform=transform, loader=pil_loader)\n",
    "    flag_loader = torch.utils.data.DataLoader(\n",
    "        dataset=flag_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return flag_loader\n",
    "\n",
    "\n",
    "def train(data_loader, epoch):\n",
    "    D.train()\n",
    "    G.train()\n",
    "\n",
    "    for batch_idx, (data, _) in enumerate(data_loader):\n",
    "        n_samples = data.size(dim=0)\n",
    "\n",
    "        #######################\n",
    "        # Train Discriminator #\n",
    "        #######################\n",
    "\n",
    "        # Zero out gradients on discriminator\n",
    "        D.zero_grad()\n",
    "\n",
    "        # Load real flag data, run through discriminator and compute BCE loss\n",
    "        # against target vector of all ones, because the flags are legit\n",
    "        real_data = Variable(data).to(device)\n",
    "        output = D(real_data)\n",
    "        real_target = Variable(torch.ones(n_samples)).to(device)\n",
    "        real_error = loss(output.squeeze(), real_target)\n",
    "\n",
    "        # Get normally distributed noise and feed to generator to create fake\n",
    "        # flag data. Run fake flag data through discriminator and compute BCE\n",
    "        # loss against target vector of all zeros, because data is fake. Detach\n",
    "        # to avoid training generator on these labels\n",
    "        noise = Variable(torch.randn(n_samples, 100, 1, 1)).to(device)\n",
    "        fake_data = G(noise)\n",
    "        output = D(fake_data.detach()).to(device)\n",
    "        fake_target = Variable(torch.zeros(n_samples)).to(device)\n",
    "        fake_error = loss(output.squeeze(), fake_target)\n",
    "\n",
    "        # Compute accumulated gradient based on real and fake data to update\n",
    "        # discriminator weights\n",
    "        d_error = real_error + fake_error\n",
    "        d_error.backward()\n",
    "        d_optim.step()\n",
    "\n",
    "        ###################\n",
    "        # Train Generator #\n",
    "        ###################\n",
    "\n",
    "        # Zero out gradients on generator\n",
    "        G.zero_grad()\n",
    "\n",
    "        # Run fake flag data through discriminator and compute BCE loss against\n",
    "        # target vector of all ones. We want to fool the discriminator, so\n",
    "        # pretend the mapped data is genuine\n",
    "        output = D(fake_data)\n",
    "        g_error = loss(output.squeeze(), real_target)\n",
    "\n",
    "        # Compute new gradients from discriminator and update weights of the\n",
    "        # generator\n",
    "        g_error.backward()\n",
    "        g_optim.step()\n",
    "\n",
    "        if epoch % epoch_test_interval == 0 and batch_idx % batch_test_interval == 0:\n",
    "            # Logging\n",
    "            print('({:02d}, {:02d}) \\tLoss_D: {:.6f} \\tLoss_G: {:.6f}'.format(\n",
    "                epoch, batch_idx, d_error.data, g_error.data))\n",
    "            \n",
    "            # Test Generator\n",
    "            with torch.no_grad():\n",
    "                sample = G(test_noise).detach().cpu()\n",
    "            grid = vutils.make_grid(sample, padding=2, normalize=True, nrow=3)\n",
    "            img = np.transpose(grid, (1,2,0)).numpy()\n",
    "            imgplot = plt.imshow(img)\n",
    "            plt.title('Epoch {}'.format(epoch))\n",
    "            plt.savefig(f\"../data/gan_progress/try4/{epoch}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G, D = Generator().to(device), Discriminator().to(device)\n",
    "loss = nn.BCELoss()\n",
    "g_optim = optim.AdamW(G.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "d_optim = optim.AdamW(D.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "flag_loader = get_flag_loader()\n",
    "noise = Variable(torch.randn(1, 100, 1, 1))\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Load previous network progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "G_file_name = \"./data/documentation/...\"\n",
    "D_file_name = \"./data/documentation/...\"\n",
    "\n",
    "G.load_state_dict(torch.load(G_file_name))\n",
    "D.load_state_dict(torch.load(D_file_name))\n",
    "\n",
    "epoch = int(re.findall(r\"net\\_G\\_e(\\d+)\", G_file_name)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(00, 00) \tLoss_D: 1.140581 \tLoss_G: 1.151804\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # Train Model\n",
    "    train(data_loader=flag_loader, epoch=epoch)\n",
    "    epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional:** Save networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G.state_dict(), f\"./data/documentation/try3.5/net_G_e{epoch}.pth\")\n",
    "torch.save(D.state_dict(), f\"./data/documentation/try3.5/net_D_e{epoch}.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
